{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "403d819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘zooms’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir zooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046703fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/jack/Desktop/HDD500/collections/Music/Blue_Mood-Robert_Munzinger.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac99df",
   "metadata": {},
   "source": [
    "# Audio_Fade in and out working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "841a2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4.\n",
      "MoviePy - Writing audio in Final_End_ZoomedTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Ensure the audio clip is the same duration as the video\n",
    "if audio_clip.duration > video_clip.duration:\n",
    "    audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "else:\n",
    "    padding_duration = video_clip.duration - audio_clip.duration\n",
    "    padding = AudioFileClip.silence(duration=padding_duration)\n",
    "    audio_clip = concatenate_audioclips([audio_clip, padding])\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = faded_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2130f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed-test.mp4.\n",
      "MoviePy - Writing audio in Final_End_Zoomed-testTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed-test.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed-test.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Ensure the audio clip is the same duration as the video\n",
    "if audio_clip.duration > video_clip.duration:\n",
    "    audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "else:\n",
    "    padding_duration = video_clip.duration - audio_clip.duration\n",
    "    padding = AudioFileClip.silence(duration=padding_duration)\n",
    "    audio_clip = concatenate_audioclips([audio_clip, padding])\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = faded_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed-test.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "01e66c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4.\n",
      "MoviePy - Writing audio in Final_End_Zoomed_With_OverlayframedTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Ensure the audio clip is the same duration as the video\n",
    "if audio_clip.duration > video_clip.duration:\n",
    "    audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "else:\n",
    "    padding_duration = video_clip.duration - audio_clip.duration\n",
    "    padding = AudioFileClip.silence(duration=padding_duration)\n",
    "    audio_clip = concatenate_audioclips([audio_clip, padding])\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 15  # seconds\n",
    "fade_out_duration = 10  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = faded_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Load the image overlay\n",
    "overlay_image = ImageClip(\"/home/jack/Desktop/StoryMaker/static/assets/Glitch_Art_Frame_512x768.png\")\n",
    "\n",
    "# Resize the overlay image to match the video dimensions\n",
    "overlay_image = overlay_image.resize(width=video_with_audio.w, height=video_with_audio.h)\n",
    "\n",
    "# Set the duration of the overlay image to match the video duration\n",
    "overlay_image = overlay_image.set_duration(video_with_audio.duration)\n",
    "\n",
    "# Composite the video with the overlay image\n",
    "final_video = CompositeVideoClip([video_with_audio, overlay_image])\n",
    "\n",
    "# Write the final video with audio and overlay to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4\"\n",
    "final_video.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "baec8980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m000000000107d1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fae44001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fae44001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fae44001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007fae64cb4900\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7fae64cc5340] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007fae64cb4900\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fae4475c3e0\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fae4475c3e0\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fae4475c3e0\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed_With_Overlayframed.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc03ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4.\n",
      "MoviePy - Writing audio in Final_End_ZoomedTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = synced_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Get the minimum duration between video and audio\n",
    "min_duration = min(video_with_audio.duration, synced_audio.duration)\n",
    "\n",
    "# Set video and audio to desired duration\n",
    "video_duration = 58  # seconds\n",
    "video_with_audio = video_with_audio.subclip(0, min(video_duration, min_duration))\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13024d",
   "metadata": {},
   "source": [
    "# Generate Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6cf60070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, AudioClip\n",
    "import numpy as np\n",
    "\n",
    "make_frame = lambda t: np.sin(440 * 2 * np.pi * t)\n",
    "clip = AudioClip(make_frame, duration=.5, fps=44100)\n",
    "clip.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2069e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plays the note A in mono (a sine wave of frequency 440 Hz)\n",
    "import numpy as np\n",
    "\n",
    "# Plays the note A in stereo (two sine waves of frequencies 440 and 880 Hz)\n",
    "make_frame = lambda t: np.array([\n",
    "    np.sin(440 * 2 * np.pi * t),\n",
    "    np.sin(880 * 2 * np.pi * t)\n",
    "]).T.copy(order=\"C\")\n",
    "clip = AudioClip(make_frame, duration=3, fps=44100)\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1f66edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as tone.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-liblensfun --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'zooms/tone.wav':\n",
      "  Duration: 00:00:03.00, bitrate: 5644 kb/s\n",
      "    Stream #0:0: Audio: pcm_f64le ([3][0][0][0] / 0x0003), 44100 Hz, stereo, dbl, 5644 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f64le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'zooms/tone.mp3':\n",
      "  Metadata:\n",
      "    TSSE            : Lavf58.29.100\n",
      "    Stream #0:0: Audio: mp3 (libmp3lame), 44100 Hz, stereo, fltp\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libmp3lame\n",
      "size=      48kB time=00:00:03.00 bitrate= 129.7kbits/s speed=56.9x    \n",
      "video:0kB audio:47kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.521832%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import subprocess\n",
    "\n",
    "# Generate the stereo audio clip\n",
    "def make_frame(t):\n",
    "    return np.array([\n",
    "        np.sin(440 * 2 * np.pi * t),\n",
    "        np.sin(880 * 2 * np.pi * t)\n",
    "    ]).T.copy(order=\"C\")\n",
    "\n",
    "duration = 3  # seconds\n",
    "fps = 44100\n",
    "sample_rate = 44100\n",
    "num_channels = 2\n",
    "num_samples = int(sample_rate * duration)\n",
    "audio_data = np.array([make_frame(t) for t in np.linspace(0, duration, num_samples)])\n",
    "\n",
    "# Save the audio data as a WAV file\n",
    "wavfile.write(\"zooms/tone.wav\", sample_rate, audio_data)\n",
    "\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"zooms/tone.wav\", \"zooms/tone.mp3\"])\n",
    "\n",
    "print(\"Audio saved as tone.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0dee88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-liblensfun --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, gif, from 'gifs/zoom_effect2.gif':\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 7064 kb/s\n",
      "    Stream #0:0: Video: gif, bgra, 512x768, 10 fps, 10 tbr, 100 tbn, 100 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (gif (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5598c3175ec0] using cpu capabilities: MMX2 SSE2Fast LZCNT SSSE3 SSE4.2\n",
      "[libx264 @ 0x5598c3175ec0] profile High 4:4:4 Predictive, level 2.2, 4:4:4 8-bit\n",
      "[libx264 @ 0x5598c3175ec0] 264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x1:0x111 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'gifs/c30bd6ca-58de-40c1-bab3-ec4df8498c4b.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv444p, 512x768, q=-1--1, 10 fps, 10240 tbn, 10 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  200 fps= 63 q=-1.0 Lsize=     814kB time=00:00:19.70 bitrate= 338.4kbits/s dup=1 drop=0 speed=6.25x    \n",
      "video:811kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.386780%\n",
      "[libx264 @ 0x5598c3175ec0] frame I:1     Avg QP:13.17  size: 83955\n",
      "[libx264 @ 0x5598c3175ec0] frame P:53    Avg QP:16.58  size: 10204\n",
      "[libx264 @ 0x5598c3175ec0] frame B:146   Avg QP:20.44  size:  1402\n",
      "[libx264 @ 0x5598c3175ec0] consecutive B-frames:  0.5%  5.0%  4.5% 90.0%\n",
      "[libx264 @ 0x5598c3175ec0] mb I  I16..4: 21.7%  0.0% 78.3%\n",
      "[libx264 @ 0x5598c3175ec0] mb P  I16..4:  2.3%  0.0%  3.2%  P16..4: 14.8% 12.1%  7.6%  0.0%  0.0%    skip:60.0%\n",
      "[libx264 @ 0x5598c3175ec0] mb B  I16..4:  0.1%  0.0%  0.0%  B16..8: 18.4%  5.0%  1.1%  direct: 1.8%  skip:73.5%  L0:37.9% L1:50.6% BI:11.5%\n",
      "[libx264 @ 0x5598c3175ec0] coded y,u,v intra: 51.1% 23.9% 28.7% inter: 7.1% 1.3% 2.1%\n",
      "[libx264 @ 0x5598c3175ec0] i16 v,h,dc,p: 71% 15% 12%  1%\n",
      "[libx264 @ 0x5598c3175ec0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 12% 23%  4%  5% 10%  3%  6%  3%\n",
      "[libx264 @ 0x5598c3175ec0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5598c3175ec0] ref P L0: 62.7% 18.5% 13.1%  5.7%\n",
      "[libx264 @ 0x5598c3175ec0] ref B L0: 91.8%  6.3%  1.9%\n",
      "[libx264 @ 0x5598c3175ec0] ref B L1: 95.5%  4.5%\n",
      "[libx264 @ 0x5598c3175ec0] kb/s:331.80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-i', 'gifs/zoom_effect2.gif', 'gifs/c30bd6ca-58de-40c1-bab3-ec4df8498c4b.mp4'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a small transparent overlay that as it get larger increates in opacity \n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import uuid\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "    \n",
    "    # Save the resulting images as a GIF animation\n",
    "    result_images[0].save('gifs/zoom_effect2.gif', save_all=True, append_images=result_images[1:], optimize=False, duration=100, loop=0)\n",
    "\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "zoom_effect(base_image_path, overlay_image_path)\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "base_filename = str(uuid.uuid4())\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"gifs/zoom_effect2.gif\", \"gifs/\"+base_filename+\".mp4\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fcee56",
   "metadata": {},
   "source": [
    "# All above is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7ede4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio clip duration: 58 seconds\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Load the audio clip\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "audio_start_time = max(58 - faded_audio.duration, 20)\n",
    "\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "audio_clip = synced_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Trim the audio clip to exactly 58 seconds\n",
    "final_audio_clip = audio_clip.subclip(0, 58)\n",
    "\n",
    "print(\"Audio clip duration:\", final_audio_clip.duration, \"seconds\")\n",
    "final_audio_clip.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "435379fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final audio clip duration: 58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-liblensfun --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'zooms/60a2bc1d-f315-4b9b-8cde-af7b5aad3fd2.wav':\n",
      "  Duration: 00:00:58.00, bitrate: 5644 kb/s\n",
      "    Stream #0:0: Audio: pcm_f64le ([3][0][0][0] / 0x0003), 44100 Hz, stereo, dbl, 5644 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f64le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'zooms/60a2bc1d-f315-4b9b-8cde-af7b5aad3fd2.mp3':\n",
      "  Metadata:\n",
      "    TSSE            : Lavf58.29.100\n",
      "    Stream #0:0: Audio: mp3 (libmp3lame), 44100 Hz, stereo, fltp\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libmp3lame\n",
      "size=     907kB time=00:00:58.01 bitrate= 128.1kbits/s speed=42.4x    \n",
      "video:0kB audio:907kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.027242%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as zooms/60a2bc1d-f315-4b9b-8cde-af7b5aad3fd2.wav\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "import random\n",
    "from scipy.io import wavfile\n",
    "import uuid\n",
    "import glob\n",
    "import random\n",
    "# Function to find a random song in the Music directory\n",
    "def music():\n",
    "    MUSIC = random.choice(glob.glob(\"/home/jack/Desktop/HDD500/collections/Music/*.mp3\"))\n",
    "    return MUSIC\n",
    "\n",
    "audio_clip = AudioFileClip(music())  # Replace with your audio file path\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 10  # seconds\n",
    "\n",
    "# Calculate the maximum possible start time to ensure the selected section fits within the audio clip\n",
    "max_start_time = audio_clip.duration - (58 - fade_in_duration - fade_out_duration)\n",
    "\n",
    "# Choose a random start time within the valid range\n",
    "random_start_time = random.uniform(0, max_start_time)\n",
    "\n",
    "# Calculate the end time based on the random start time and desired total duration\n",
    "random_end_time = random_start_time + (58 - fade_out_duration)\n",
    "\n",
    "# Extract the random section from the audio clip\n",
    "random_section = audio_clip.subclip(random_start_time, random_end_time)\n",
    "\n",
    "# Apply fade-in and fade-out effects\n",
    "faded_audio = random_section.audio_fadein(fade_in_duration).audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Make sure the resulting audio clip is exactly 58 seconds long\n",
    "final_audio_clip = faded_audio.subclip(0, 58)\n",
    "\n",
    "# Print the duration of the final audio clip\n",
    "print(\"Final audio clip duration:\", final_audio_clip.duration, \"seconds\")\n",
    "\n",
    "# Preview the final audio clip\n",
    "final_audio_clip.preview()\n",
    "\n",
    "base_filename = str(uuid.uuid4())\n",
    "# Save the audio as a WAV file\n",
    "clip=final_audio_clip\n",
    "wavfile.write(\"zooms/\"+base_filename+\".wav\", int(clip.fps), clip.to_soundarray())\n",
    "import subprocess\n",
    "\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"zooms/\"+base_filename+\".wav\", \"zooms/\"+base_filename+\".mp3\"])\n",
    "\n",
    "print(\"Audio saved as zooms/\"+base_filename+\".wav\")\n",
    "\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faafa175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m00000000007361a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc zooms/audio02b.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92cb9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-liblensfun --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'zooms/audio02.wav':\n",
      "  Duration: 00:00:58.00, bitrate: 5644 kb/s\n",
      "    Stream #0:0: Audio: pcm_f64le ([3][0][0][0] / 0x0003), 44100 Hz, stereo, dbl, 5644 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f64le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'zooms/audio02.mp3':\n",
      "  Metadata:\n",
      "    TSSE            : Lavf58.29.100\n",
      "    Stream #0:0: Audio: mp3 (libmp3lame), 44100 Hz, stereo, fltp\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libmp3lame\n",
      "size=     512kB time=00:00:39.08 bitrate= 107.3kbits/s speed=39.1x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as zooms/audio02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "size=     907kB time=00:00:58.01 bitrate= 128.1kbits/s speed=39.1x    \n",
      "video:0kB audio:907kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.027242%\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "# Save an audio clip as a WAV file\n",
    "clip=final_audio_clip\n",
    "wavfile.write(\"zooms/audio02.wav\", int(clip.fps), clip.to_soundarray())\n",
    "import subprocess\n",
    "\n",
    "# Convert the WAV file to MP3 using FFmpeg\n",
    "subprocess.run([\"ffmpeg\", \"-i\", \"zooms/audio02.wav\", \"zooms/audio02.mp3\"])\n",
    "\n",
    "print(\"Audio saved as zooms/audio02.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1711935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random section duration: 1.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# working but not wanted\n",
    "from moviepy.editor import VideoFileClip\n",
    "import random\n",
    "\n",
    "# Load the video clip\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "\n",
    "# Define the desired duration of the random section\n",
    "desired_duration = 1  # seconds\n",
    "\n",
    "# Calculate the maximum possible start time to ensure the selected section fits within the video\n",
    "max_start_time = video_clip.duration - desired_duration\n",
    "\n",
    "# Choose a random start time within the valid range\n",
    "random_start_time = random.uniform(0, max_start_time)\n",
    "\n",
    "# Extract the random section from the video\n",
    "random_section = video_clip.subclip(random_start_time, random_start_time + desired_duration)\n",
    "\n",
    "# Print the duration of the random section\n",
    "print(\"Random section duration:\", random_section.duration, \"seconds\")\n",
    "\n",
    "# Preview the random section\n",
    "random_section.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "56d2081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio clip duration: 341.87 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m audio_clip \u001b[38;5;241m=\u001b[39m synced_audio\u001b[38;5;241m.\u001b[39maudio_fadeout(fade_out_duration)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio clip duration:\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio_clip\u001b[38;5;241m.\u001b[39mduration, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43maudio_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-118>:2\u001b[0m, in \u001b[0;36mpreview\u001b[0;34m(clip, fps, buffersize, nbytes, audioFlag, videoFlag)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/audio/io/preview.py:62\u001b[0m, in \u001b[0;36mpreview\u001b[0;34m(clip, fps, buffersize, nbytes, audioFlag, videoFlag)\u001b[0m\n\u001b[1;32m     60\u001b[0m chunk \u001b[38;5;241m=\u001b[39m pg\u001b[38;5;241m.\u001b[39msndarray\u001b[38;5;241m.\u001b[39mmake_sound(sndarray)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m channel\u001b[38;5;241m.\u001b[39mget_queue():\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m videoFlag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m videoFlag\u001b[38;5;241m.\u001b[39mis_set():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, AudioClip\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 10  # seconds\n",
    "fade_out_duration = 15  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "\n",
    "#audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "audio_start_time = max(58 - faded_audio.duration, 20)\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "audio_clip = synced_audio.audio_fadeout(fade_out_duration)\n",
    "print(\"Audio clip duration:\", audio_clip.duration, \"seconds\")\n",
    "audio_clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Load the audio clip\n",
    "audio_clip = AudioFileClip(\"your_audio_file.mp3\")  # Replace with your audio file path\n",
    "\n",
    "# Print the duration of the audio clip\n",
    "print(\"Audio clip duration:\", audio_clip.duration, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "36d4333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m00000000019811a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc zooms/audio01.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fbf7251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<moviepy.audio.io.AudioFileClip.AudioFileClip object at 0x7fe61f3fbee0>\n"
     ]
    }
   ],
   "source": [
    "print(audio_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.fx(audio_fadein, \"00:00:06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c396e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/HDD500/collections/Music/DesertPlanet.mp3\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/abd0aebb-ce72-4a30-a233-14ee14f5b841random_video_58s.mp4\")\n",
    "clip = AudioFileClip(music())\n",
    "clip.fx(audio_fadein, \"00:00:10\")\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e45f836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = AudioFileClip(music())\n",
    "\n",
    "clip.fx(audio_fadein, \"00:00:26\")\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb9226f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import moviepy.audio.fx.all as afx\n",
    "clip = AudioFileClip(music())\n",
    "\n",
    "clip.fx(afx.audio_fadein, \"00:00:26\")\n",
    "\n",
    "clip.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "117cc291",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_fadein' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m clip \u001b[38;5;241m=\u001b[39m AudioFileClip(music())\n\u001b[0;32m----> 3\u001b[0m clip\u001b[38;5;241m.\u001b[39mfx(\u001b[43maudio_fadein\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00:00:06\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio_fadein' is not defined"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "clip = AudioFileClip(music())\n",
    "clip.fx(audio_fadein, \"00:00:06\")\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "Cell In[43], line 3\n",
    "      1 clip = AudioFileClip(music())\n",
    "----> 3 clip.fx(audio_fadein, \"00:00:06\")\n",
    "\n",
    "NameError: name 'audio_fadein' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54198dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/HDD500/collections/Music/Sinister-Anno_Domini_Beats.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply fade in effect to audio\u001b[39;00m\n\u001b[1;32m     15\u001b[0m clip\u001b[38;5;241m.\u001b[39mfx(audio_fadein, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00:00:20\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#faded_audio = audio_clip.fx.fadein(fade_in_duration)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate the duration for synchronization\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-118>:2\u001b[0m, in \u001b[0;36mpreview\u001b[0;34m(clip, fps, buffersize, nbytes, audioFlag, videoFlag)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/audio/io/preview.py:62\u001b[0m, in \u001b[0;36mpreview\u001b[0;34m(clip, fps, buffersize, nbytes, audioFlag, videoFlag)\u001b[0m\n\u001b[1;32m     60\u001b[0m chunk \u001b[38;5;241m=\u001b[39m pg\u001b[38;5;241m.\u001b[39msndarray\u001b[38;5;241m.\u001b[39mmake_sound(sndarray)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m channel\u001b[38;5;241m.\u001b[39mget_queue():\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m videoFlag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m videoFlag\u001b[38;5;241m.\u001b[39mis_set():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/abd0aebb-ce72-4a30-a233-14ee14f5b841random_video_58s.mp4\")\n",
    "clip = AudioFileClip(music())\n",
    "\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 1  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "clip.fx(audio_fadein, \"00:00:20\")\n",
    "clip.preview()\n",
    "\n",
    "\n",
    "#faded_audio = audio_clip.fx.fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "#audio_start_time = max(video_clip.duration - faded_audio.duration, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3709ee67",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "audio_fadeout() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m trimmed_audio \u001b[38;5;241m=\u001b[39m faded_audio\u001b[38;5;241m.\u001b[39msubclip(\u001b[38;5;241m0\u001b[39m, video_clip\u001b[38;5;241m.\u001b[39mduration)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Apply fade out effect to audio at the end\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m final_audio \u001b[38;5;241m=\u001b[39m \u001b[43mtrimmed_audio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_fadeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrimmed_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfade_out_duration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Set audio of the video to the processed audio\u001b[39;00m\n\u001b[1;32m     22\u001b[0m video_with_audio \u001b[38;5;241m=\u001b[39m video_clip\u001b[38;5;241m.\u001b[39mset_audio(final_audio)\n",
      "\u001b[0;31mTypeError\u001b[0m: audio_fadeout() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 5  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_fadein(audio_clip, fade_in_duration)\n",
    "\n",
    "# Trim the audio to match the video duration\n",
    "trimmed_audio = faded_audio.subclip(0, video_clip.duration)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = trimmed_audio.audio_fadeout(trimmed_audio, fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zommed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "800b2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/HDD500/collections/Music/ChrisHaugen.mp3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write_videofile() got an unexpected keyword argument 'duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Write the final video with audio to a file\u001b[39;00m\n\u001b[1;32m     30\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mvideo_with_audio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_videofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m58\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibx264\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: write_videofile() got an unexpected keyword argument 'duration'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.audio.fx.all import audio_fadein\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 5  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Apply fade in effect to audio\n",
    "faded_audio = audio_clip.audio_fadein(fade_in_duration)\n",
    "\n",
    "# Calculate the duration for synchronization\n",
    "audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "\n",
    "# Set audio to start at the calculated point\n",
    "synced_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Apply fade out effect to audio at the end\n",
    "final_audio = synced_audio.audio_fadeout(fade_out_duration)\n",
    "\n",
    "# Set audio of the video to the processed audio\n",
    "video_with_audio = video_clip.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "output_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/Final_End_Zoomed.mp4\"\n",
    "video_with_audio.write_videofile(output_path, duration=58,codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85df2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8413eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m0000000000d3b1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6904001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6904001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6904001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007f692ccd84f0\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f692cce9180] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007f692ccd84f0\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6904759190\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6904759190\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f6904759190\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f692cd4ebc0] \u001b[0m\u001b[1;31mget_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cd4ebc0] \u001b[0m\u001b[1;31mthread_get_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cd4ebc0] \u001b[0m\u001b[1;31mdecode_slice_header error\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cd4ebc0] \u001b[0m\u001b[1;31mno frame!\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cce9180] \u001b[0m\u001b[1;31mget_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cce9180] \u001b[0m\u001b[1;31mthread_get_buffer() failed\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cce9180] \u001b[0m\u001b[1;31mdecode_slice_header error\n",
      "\u001b[0m\u001b[0;36m[h264 @ 0x7f692cce9180] \u001b[0m\u001b[1;31mno frame!\n",
      "\u001b[0mQObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c02e501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/HDD500/collections/Music/Alpha_Mission-Jimena_Contreras.mp3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AudioFileClip' object has no attribute 'crossfadein'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m fade_out_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# seconds\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fade in audio\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m faded_audio \u001b[38;5;241m=\u001b[39m \u001b[43maudio_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossfadein\u001b[49m(fade_in_duration)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Calculate the point at which to start audio to synchronize with the video\u001b[39;00m\n\u001b[1;32m     16\u001b[0m audio_start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(video_clip\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m-\u001b[39m faded_audio\u001b[38;5;241m.\u001b[39mduration, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AudioFileClip' object has no attribute 'crossfadein'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
    "from MUSIC import music\n",
    "print (music())\n",
    "# Load video and audio clips\n",
    "video_clip = VideoFileClip(\"/home/jack/Desktop/abd0aebb-ce72-4a30-a233-14ee14f5b841random_video_58s.mp4\")\n",
    "audio_clip = AudioFileClip(music())\n",
    "\n",
    "# Define fade durations\n",
    "fade_in_duration = 1  # seconds\n",
    "fade_out_duration = 1  # seconds\n",
    "\n",
    "# Fade in audio\n",
    "faded_audio = audio_clip.crossfadein(fade_in_duration)\n",
    "\n",
    "# Calculate the point at which to start audio to synchronize with the video\n",
    "audio_start_time = max(video_clip.duration - faded_audio.duration, 0)\n",
    "\n",
    "# Trim audio to match video duration\n",
    "trimmed_audio = faded_audio.subclip(audio_start_time)\n",
    "\n",
    "# Concatenate video with trimmed audio\n",
    "video_with_audio = video_clip.set_audio(trimmed_audio)\n",
    "\n",
    "# Fade out audio at the end of the video\n",
    "final_audio = video_with_audio.audio.crossfadeout(fade_out_duration)\n",
    "\n",
    "# Set the audio of the video to the faded-out audio\n",
    "final_video = video_with_audio.set_audio(final_audio)\n",
    "\n",
    "# Write the final video with audio to a file\n",
    "final_video.write_videofile(\"/home/jack/Desktop/StoryMaker/VIDEOS/uuidoutput.mp4\", codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e9a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/jack/hidden/MUSIC.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/jack/hidden/MUSIC.py\n",
    "import glob\n",
    "import random\n",
    "def music():\n",
    "    MUSIC = random.choice(glob.glob(\"/home/jack/Desktop/HDD500/collections/Music/*.mp3\"))\n",
    "    return MUSIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501b3645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/StoryMaker\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63290834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/HDD500/collections/Music/Keep_On_Movin-King_Canyon.mp3\n"
     ]
    }
   ],
   "source": [
    "from MUSIC import music\n",
    "print (music())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9395cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.png\n",
    "!rm *.jpg\n",
    "!rm start/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4df5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def zoom_effect(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    # Start with the original image\n",
    "    current_image = original_image.copy()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Enlarge the current image by 1%\n",
    "        new_size = (int(w * 1.01), int(h * 1.01))\n",
    "        enlarged_image = current_image.resize(new_size, Image.BICUBIC)\n",
    "        sm_size = ((int((w/w) * 1.01)+1+w), (int(h/h * 1.01))+1+h)\n",
    "        print(sm_size)\n",
    "        shrunken_image = current_image.resize(sm_size, Image.BICUBIC)        \n",
    "        # Calculate the top-left coordinates to crop back to the original size\n",
    "        x_offset = (new_size[0] - w) // 2\n",
    "        y_offset = (new_size[1] - h) // 2\n",
    "\n",
    "        # Crop back to the original size\n",
    "        cropped_image = enlarged_image.crop((x_offset, y_offset, x_offset + w, y_offset + h))\n",
    "        shrunken_image.save(\"start/\"+str(i)+\".png\")\n",
    "        # Save the current image with zoom effect\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.jpg\"\n",
    "        cropped_image = cropped_image.convert(\"RGB\")\n",
    "        cropped_image.save(output_path)\n",
    "\n",
    "        # Set the current image to the cropped image for the next iteration\n",
    "        current_image = cropped_image.copy()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 150  # Change this to the desired number of images in the sequence\n",
    "\n",
    "zoom_effect(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_image.width) // 2\n",
    "        y_offset = (h - overlay_image.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(resized_original, overlay)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a580b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_image.width) // 2\n",
    "        y_offset = (h - overlay_image.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(resized_original, overlay)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images, save_interval=10):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new transparent image with the same size as the original image\n",
    "        overlay_image = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, ((w - size[0]) // 2, (h - size[1]) // 2))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the transparent image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "        # Save the image at specified intervals to free up memory\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            final_image.close()\n",
    "\n",
    "    # Save the last image to ensure it is not left open\n",
    "    final_image.close()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "save_interval = 10  # Change this to adjust how often images are saved\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images, save_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d88c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6854a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Calculate the size of the overlay image based on the increase factor (inc)\n",
    "        overlay_w, overlay_h = int(w * inc), int(h * inc)\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the original image\n",
    "        x_offset = (w - overlay_w) // 2\n",
    "        y_offset = (h - overlay_h) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        # Set the opacity for the overlay\n",
    "        overlay.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by alpha compositing the original image and the overlay\n",
    "        final_image = Image.alpha_composite(original_image, overlay)\n",
    "\n",
    "        # Create a zoomed version of the background image\n",
    "        zoomed_image = original_image.resize((int(w / inc), int(h / inc)), Image.BICUBIC)\n",
    "        x_zoom_offset = (w - zoomed_image.width) // 2\n",
    "        y_zoom_offset = (h - zoomed_image.height) // 2\n",
    "\n",
    "        # Paste the zoomed image onto the final image at the calculated coordinates\n",
    "        final_image.paste(zoomed_image, (x_zoom_offset, y_zoom_offset))\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"start/00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new transparent image with the same size as the original image\n",
    "        overlay_image = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, ((w - size[0]) // 2, (h - size[1]) // 2))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the transparent image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 100  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Resize and set opacity for the overlay image\n",
    "        overlay_image = overlay_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8369e656",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00007.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Change this to the desired number of images in the sequence\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43moverlay_images_with_opacity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_images\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 23\u001b[0m, in \u001b[0;36moverlay_images_with_opacity\u001b[0;34m(image_path, num_images)\u001b[0m\n\u001b[1;32m     20\u001b[0m overlay_image\u001b[38;5;241m.\u001b[39mputalpha(opacity)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Create the final image by overlaying the resized image onto the original image\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m final_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzooms/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m file_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:3299\u001b[0m, in \u001b[0;36malpha_composite\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m   3297\u001b[0m im1\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   3298\u001b[0m im2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m-> 3299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im1\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: images do not match"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with an alpha channel for overlaying\n",
    "        overlay_image = Image.new(\"RGBA\", size, (0, 0, 0, 0))\n",
    "        overlay_image.paste(resized_original, (0, 0))\n",
    "\n",
    "        # Set opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "        DIR = \"zooms/\"\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{DIR}{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00007.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "874a5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir zooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bcf4a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/StoryMaker\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a copy of the original image for each overlay\n",
    "        overlay_image = original_image.copy()\n",
    "\n",
    "        # Resize and set opacity for the overlay image\n",
    "        overlay_image = overlay_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Create the final image by overlaying the resized image onto the original image\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        overlay_image = original_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        final_image = Image.alpha_composite(original_image, overlay_image)\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        size = (int(w * inc), int(h * inc))\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        overlay_image = original_image.resize(size, Image.BICUBIC)\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        final_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n",
    "        x_offset = (w - size[0]) // 2\n",
    "        y_offset = (h - size[1]) // 2\n",
    "        final_image.paste(overlay_image, (x_offset, y_offset))\n",
    "\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"00001.jpg\"\n",
    "num_images = 10  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e89099",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls leonardo.ai_files/00001.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f75288",
   "metadata": {},
   "outputs": [],
   "source": [
    "leonardo.ai_files/00001.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7838bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_centered(larger_image_path, output_path, inc):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w, h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w - inc), int(h - inc)), Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    larger_image.save(output_path)\n",
    "\n",
    "larger_image_path = \"leonardo.ai_files/00001.jpg\"\n",
    "for Inc in range(0, 100):\n",
    "    inc = Inc + 0.5\n",
    "    output_path = str(inc) + \"test.png\"\n",
    "    print(inc)\n",
    "    overlay_centered(larger_image_path, output_path, inc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "def overlay_centered(larger_image_path, inc, image_num):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w, h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w + inc), int(h + inc)), Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    output_directory = \"start/\"\n",
    "    ext = \".png\"\n",
    "    save_path = os.path.join(output_directory, f\"{image_num:05d}{ext}\")\n",
    "    larger_image.save(save_path)\n",
    "\n",
    "\n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\"\n",
    "image_num = 1\n",
    "for inc in range(1, 1000):\n",
    "    print(inc)\n",
    "    overlay_centered(larger_image_path, inc, image_num)\n",
    "    image_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /home/jack/Desktop/learn_flask/zoom.ipynb ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def search_in_ipynb_files(root_directory, term):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        for filename in fnmatch.filter(filenames, \"*.ipynb\"):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                lines = file.readlines()\n",
    "                for line_number, line in enumerate(lines, 1):\n",
    "                    if term in line:\n",
    "                        print(f\"Found '{term}' in file: {file_path}, line: {line_number}\")\n",
    "                        print(\"XXXXXXX\",line.strip())  # Print the whole line\n",
    "\n",
    "# Example usage\n",
    "root_directory = \"/home/jack/Desktop\"\n",
    "term_to_search = \"composit\"\n",
    "search_in_ipynb_files(root_directory, term_to_search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59b18f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m inc \u001b[38;5;241m=\u001b[39m inc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.1\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(inc)\n\u001b[0;32m---> 39\u001b[0m \u001b[43moverlay_centered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlarger_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43minc\u001b[49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[0;32mIn[73], line 22\u001b[0m, in \u001b[0;36moverlay_centered\u001b[0;34m(larger_image_path, inc)\u001b[0m\n\u001b[1;32m     19\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m zfill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(inc)\n\u001b[0;32m---> 22\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mzfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m larger_image\u001b[38;5;241m.\u001b[39msave(save_path)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def overlay_centered(larger_image_path,inc):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    w,h = larger_image.size\n",
    "    smaller_image = larger_image.resize((int(w*inc),int(h*inc)),Image.BICUBIC)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.size\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "    ext = \".png\"\n",
    "    output_directory = \"start/\"\n",
    "    \n",
    "    zfill = int(inc)\n",
    "    save_path = os.path.join(output_directory, f\"{zfill(5)}{ext}\")\n",
    "    larger_image.save(save_path)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save the final image\n",
    "    #larger_image.save(\"start/\"+str(inc)+\"test.png\")\n",
    "    \n",
    "    \n",
    "larger_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\" \n",
    "larger_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\" \n",
    "for inc in range(1,100):\n",
    "    inc = inc*.1\n",
    "    print(inc)\n",
    "    \n",
    "    overlay_centered(larger_image_path,inc)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6196dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef543cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_centered(larger_image_path, smaller_image_path, output_path):\n",
    "    # Open the larger and smaller images\n",
    "    larger_image = Image.open(larger_image_path).convert(\"RGBA\")\n",
    "    smaller_image = Image.open(smaller_image_path).convert(\"RGBA\")\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    width_larger, height_larger = larger_image.size\n",
    "    width_smaller, height_smaller = smaller_image.resize((400,400),Image.BICUBIC)\n",
    "\n",
    "    # Calculate the center coordinates\n",
    "    center_x = (width_larger - width_smaller) // 2\n",
    "    center_y = (height_larger - height_smaller) // 2\n",
    "\n",
    "    # Overlay the smaller image on the larger image\n",
    "    larger_image.paste(smaller_image, (center_x, center_y), smaller_image)\n",
    "\n",
    "    # Save the final image\n",
    "    larger_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "larger_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00001.jpg\"\n",
    "smaller_image_path = \"/home/jack/Desktop/learn_flask/static/abstract_beauty/00004.jpg\"\n",
    "output_path = \"output_image.png\"\n",
    "\n",
    "overlay_centered(larger_image_path, smaller_image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!display output_image.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "785ca240",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Create the overlay images\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43moverlay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Create the video from the overlay images\u001b[39;00m\n\u001b[1;32m     51\u001b[0m create_overlay_video(output_directory, output_video_path, fps)\n",
      "Cell \u001b[0;32mIn[76], line 24\u001b[0m, in \u001b[0;36moverlay_images\u001b[0;34m(base_image_path, overlay_image_path, output_directory, num_steps)\u001b[0m\n\u001b[1;32m     21\u001b[0m new_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m, (width, height), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Overlay the resized overlay image on the new image with the calculated opacity\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m new_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresized_overlay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Overlay the new image on the base image with the calculated opacity\u001b[39;00m\n\u001b[1;32m     27\u001b[0m final_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39malpha_composite(base_image, new_image)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:3299\u001b[0m, in \u001b[0;36malpha_composite\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m   3297\u001b[0m im1\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   3298\u001b[0m im2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m-> 3299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im1\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: images do not match"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0699e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Desktop/learn_flask\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52292c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Create the overlay video\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43moverlay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36moverlay_images\u001b[0;34m(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\u001b[0m\n\u001b[1;32m     27\u001b[0m     clips\u001b[38;5;241m.\u001b[39mappend(composite_clip)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Concatenate all clips to create the final video\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m final_clip \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_videoclips\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclips\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Write the video to a file\u001b[39;00m\n\u001b[1;32m     33\u001b[0m final_clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_video_path, fps\u001b[38;5;241m=\u001b[39mfps, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m'\u001b[39m, audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/compositing/concatenate.py:71\u001b[0m, in \u001b[0;36mconcatenate_videoclips\u001b[0;34m(clips, method, transition, bg_color, ismask, padding)\u001b[0m\n\u001b[1;32m     68\u001b[0m     clips \u001b[38;5;241m=\u001b[39m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m+\u001b[39m y, l) \u001b[38;5;241m+\u001b[39m [clips[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     69\u001b[0m     transition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m tt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclips\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m sizes \u001b[38;5;241m=\u001b[39m [v\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m clips]\n\u001b[1;32m     75\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sizes)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2571\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumsum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;124;03m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2569\u001b[0m \n\u001b[1;32m   2570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcumsum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = VideoFileClip(base_image_path, target_resolution=(720, 1280))\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (width * (1.0 + i * step_size), height * (1.0 + i * step_size))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    # Concatenate all clips to create the final video\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "\n",
    "    # Write the video to a file\n",
    "    final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/vid-from-images.mp4\"\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7fe4c38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip 0 Duration: None\n",
      "Clip 1 Duration: None\n",
      "Clip 2 Duration: None\n",
      "Clip 3 Duration: None\n",
      "Clip 4 Duration: None\n",
      "Clip 5 Duration: None\n",
      "Clip 6 Duration: None\n",
      "Clip 7 Duration: None\n",
      "Clip 8 Duration: None\n",
      "Clip 9 Duration: None\n",
      "Clip 10 Duration: None\n",
      "Clip 11 Duration: None\n",
      "Clip 12 Duration: None\n",
      "Clip 13 Duration: None\n",
      "Clip 14 Duration: None\n",
      "Clip 15 Duration: None\n",
      "Clip 16 Duration: None\n",
      "Clip 17 Duration: None\n",
      "Clip 18 Duration: None\n",
      "Clip 19 Duration: None\n",
      "Clip 20 Duration: None\n",
      "Clip 21 Duration: None\n",
      "Clip 22 Duration: None\n",
      "Clip 23 Duration: None\n",
      "Clip 24 Duration: None\n",
      "Clip 25 Duration: None\n",
      "Clip 26 Duration: None\n",
      "Clip 27 Duration: None\n",
      "Clip 28 Duration: None\n",
      "Clip 29 Duration: None\n",
      "Clip 30 Duration: None\n",
      "Clip 31 Duration: None\n",
      "Clip 32 Duration: None\n",
      "Clip 33 Duration: None\n",
      "Clip 34 Duration: None\n",
      "Clip 35 Duration: None\n",
      "Clip 36 Duration: None\n",
      "Clip 37 Duration: None\n",
      "Clip 38 Duration: None\n",
      "Clip 39 Duration: None\n",
      "Clip 40 Duration: None\n",
      "Clip 41 Duration: None\n",
      "Clip 42 Duration: None\n",
      "Clip 43 Duration: None\n",
      "Clip 44 Duration: None\n",
      "Clip 45 Duration: None\n",
      "Clip 46 Duration: None\n",
      "Clip 47 Duration: None\n",
      "Clip 48 Duration: None\n",
      "Clip 49 Duration: None\n",
      "Clip 50 Duration: None\n",
      "Error while concatenating clips: unsupported operand type(s) for +: 'int' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "import numpy as np\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = VideoFileClip(base_image_path, target_resolution=(720, 1280))\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (width * (1.0 + i * step_size), height * (1.0 + i * step_size))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Print the duration of the resized overlay clip for debugging\n",
    "        print(\"Clip\", i, \"Duration:\", resized_overlay_clip.duration)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"xooms/output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fb3d845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while concatenating clips: unsupported operand type(s) for +: 'int' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"zooms/output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71454ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56ccfe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while concatenating clips: unsupported operand type(s) for +: 'int' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "        composite_clip = composite_clip.set_duration(base_clip.duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips)\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"zooms/output_video.mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c0398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba24a2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGBA size=512x768>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "    # Save the resulting images as a GIF animation\n",
    "    result_images[0].save('gifs/zoom_effect2.gif', save_all=True, append_images=result_images[1:], optimize=False, duration=100, loop=0)\n",
    "#zoom_effect(bg_file, fg_file)\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "zoom_effect(base_image_path, overlay_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48478ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m frames_per_second \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     38\u001b[0m images_list \u001b[38;5;241m=\u001b[39m zoom_effect(bg_file_path, fg_file_path)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcreate_mp4_from_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mp4_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_per_second\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mcreate_mp4_from_images\u001b[0;34m(images_list, output_file, fps)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mp4_from_images\u001b[39m(images_list, output_file, fps):\n\u001b[0;32m---> 28\u001b[0m     clip \u001b[38;5;241m=\u001b[39m \u001b[43mImageSequenceClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_file, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m, fps\u001b[38;5;241m=\u001b[39mfps)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/io/ImageSequenceClip.py:84\u001b[0m, in \u001b[0;36mImageSequenceClip.__init__\u001b[0;34m(self, sequence, fps, durations, with_mask, ismask, load_images)\u001b[0m\n\u001b[1;32m     82\u001b[0m    size \u001b[38;5;241m=\u001b[39m imread(sequence[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m    size \u001b[38;5;241m=\u001b[39m \u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m     87\u001b[0m     image1\u001b[38;5;241m=\u001b[39mimage\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    512\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    516\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[0;32m--> 519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "\n",
    "\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16785579",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m frames_per_second \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     36\u001b[0m images_list \u001b[38;5;241m=\u001b[39m zoom_effect(bg_file_path, fg_file_path)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mcreate_mp4_from_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mp4_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_per_second\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mcreate_mp4_from_images\u001b[0;34m(images_list, output_file, fps)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mp4_from_images\u001b[39m(images_list, output_file, fps):\n\u001b[0;32m---> 28\u001b[0m     clip \u001b[38;5;241m=\u001b[39m \u001b[43mImageSequenceClip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     clip\u001b[38;5;241m.\u001b[39mwrite_videofile(output_file, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m, fps\u001b[38;5;241m=\u001b[39mfps)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/io/ImageSequenceClip.py:84\u001b[0m, in \u001b[0;36mImageSequenceClip.__init__\u001b[0;34m(self, sequence, fps, durations, with_mask, ismask, load_images)\u001b[0m\n\u001b[1;32m     82\u001b[0m    size \u001b[38;5;241m=\u001b[39m imread(sequence[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m    size \u001b[38;5;241m=\u001b[39m \u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m     87\u001b[0m     image1\u001b[38;5;241m=\u001b[39mimage\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    512\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    516\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[0;32m--> 519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "fg_file_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5488366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video2.mp4.\n",
      "Moviepy - Writing video output_video2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video2.mp4\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "    \n",
    "    return result_images  # Move the return statement outside the for loop\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    # Convert PIL Image objects to NumPy arrays\n",
    "    image_arrays = [np.array(image) for image in images_list]\n",
    "    \n",
    "    # Create the video clip from the NumPy arrays\n",
    "    clip = ImageSequenceClip(image_arrays, fps=fps)\n",
    "    \n",
    "    # Write the video to the output file\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "fg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_mp4_file = \"output_video2.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31bd9afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m000000000121feb0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "[\u001b[32;1m00007fb4040016c0\u001b[0m] filesystem stream error: \u001b[31;1mcannot open file /home/jack/Desktop/learn_flask/output_video2 (No such file or directory)\u001b[0m\n",
      "[\u001b[32;1m00007fb420001db0\u001b[0m] filesystem stream error: \u001b[31;1mcannot open file /home/jack/Desktop/learn_flask/output_video2 (No such file or directory)\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output_video2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c44f9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "def zoom_effect(bg_file, fg_file):\n",
    "    bg = Image.open(bg_file).convert('RGBA')\n",
    "    SIZE = bg.size\n",
    "    bg = bg.resize((SIZE), Image.BICUBIC)\n",
    "    fg = Image.open(fg_file).convert('RGBA')\n",
    "    fg = fg.resize((SIZE), Image.BICUBIC)\n",
    "    fg_copy = fg.copy()\n",
    "    fg_copy = fg_copy.resize((int(fg_copy.width), int(fg_copy.height)))\n",
    "    result_images = []\n",
    "    for i in range(200):\n",
    "        size = (int(fg_copy.width * (i+1)/200), int(fg_copy.height * (i+1)/200))\n",
    "        fg_copy_resized = fg_copy.resize(size)\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        fg_copy_resized = fg_copy_resized.convert('RGBA')\n",
    "        fg_copy_resized.putalpha(int((i+1)*255/200))\n",
    "        result = bg.copy()\n",
    "        x = int((bg.width - fg_copy_resized.width)/2)\n",
    "        y = int((bg.height - fg_copy_resized.height)/2)\n",
    "        result.alpha_composite(fg_copy_resized, (x, y))\n",
    "        #result.save(\"gifs/_\"+str(i)+\".png\")\n",
    "        result_images.append(result)\n",
    "        return result_images\n",
    "\n",
    "def create_mp4_from_images(images_list, output_file, fps):\n",
    "    # Convert PIL Image objects to NumPy arrays\n",
    "    image_arrays = [np.array(image) for image in images_list]\n",
    "    \n",
    "    # Create the video clip from the NumPy arrays\n",
    "    clip = ImageSequenceClip(image_arrays, fps=fps)\n",
    "    \n",
    "    # Write the video to the output file\n",
    "    clip.write_videofile(output_file, codec=\"libx264\", fps=fps)\n",
    "\n",
    "bg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "fg_file_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_mp4_file = \"output_video.mp4\"\n",
    "frames_per_second = 30\n",
    "\n",
    "images_list = zoom_effect(bg_file_path, fg_file_path)\n",
    "create_mp4_from_images(images_list, output_mp4_file, frames_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f5103c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4055: error: (-215:Assertion failed) inv_scale_x > 0 in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Create the overlay video\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43moverlay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 20\u001b[0m, in \u001b[0;36moverlay_images\u001b[0;34m(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\u001b[0m\n\u001b[1;32m     17\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(width \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m i \u001b[38;5;241m*\u001b[39m step_size)), \u001b[38;5;28mint\u001b[39m(height \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m i \u001b[38;5;241m*\u001b[39m step_size)))  \u001b[38;5;66;03m# Inverse size calculation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Resize both clips to have the same size\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m resized_base_clip \u001b[38;5;241m=\u001b[39m \u001b[43mbase_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m resized_overlay_clip \u001b[38;5;241m=\u001b[39m overlay_clip\u001b[38;5;241m.\u001b[39mresize(size)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Set the opacity of the overlay clip\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/fx/resize.py:152\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(clip, newsize, height, width, apply_to_mask)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     fl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pic: resizer(pic\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m), newsize)\n\u001b[0;32m--> 152\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfl_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to_mask \u001b[38;5;129;01mand\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m resize(clip\u001b[38;5;241m.\u001b[39mmask, newsize, apply_to_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m<decorator-gen-90>:2\u001b[0m, in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/decorators.py:14\u001b[0m, in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m newclip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newclip\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/VideoClip.py:936\u001b[0m, in \u001b[0;36mImageClip.fl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 936\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mimage_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t: arr\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/fx/resize.py:150\u001b[0m, in \u001b[0;36mresize.<locals>.<lambda>\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    147\u001b[0m     fl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pic: \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39mresizer((\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m pic)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m), newsize)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     fl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pic: \u001b[43mresizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m newclip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mfl_image(fl)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to_mask \u001b[38;5;129;01mand\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/moviepy/video/fx/resize.py:16\u001b[0m, in \u001b[0;36mresizer\u001b[0;34m(pic, newsize)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# For dowsizing use area to prevent aliasing\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mly\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4055: error: (-215:Assertion failed) inv_scale_x > 0 in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    base_duration = num_steps / fps\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 - i * step_size)), int(height * (1.0 - i * step_size)))  # Inverse size calculation\n",
    "\n",
    "        # Resize both clips to have the same size\n",
    "        resized_base_clip = base_clip.resize(size)\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([resized_base_clip, resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 50\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4008781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m000000000163d1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fa39c001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fa39c001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fa39c001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007fa3b0c09920\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7fa3b0c1be80] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007fa3b0c09920\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fa39c766340\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fa39c766340\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007fa39c766340\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3f3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "669dea3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 157\u001b[0m\n\u001b[1;32m    154\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Create the overlay images\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[43moverlay_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Create the video from the overlay images\u001b[39;00m\n\u001b[1;32m    160\u001b[0m create_overlay_video(output_directory, output_video_path, fps)\n",
      "Cell \u001b[0;32mIn[82], line 133\u001b[0m, in \u001b[0;36moverlay_images\u001b[0;34m(base_image_path, overlay_image_path, output_directory, num_steps)\u001b[0m\n\u001b[1;32m    130\u001b[0m new_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m, (width, height), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overlay the resized overlay image on the new image with the calculated opacity\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m new_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresized_overlay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overlay the new image on the base image with the calculated opacity\u001b[39;00m\n\u001b[1;32m    136\u001b[0m final_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39malpha_composite(base_image, new_image)\n",
      "File \u001b[0;32m~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL/Image.py:3299\u001b[0m, in \u001b[0;36malpha_composite\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m   3297\u001b[0m im1\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   3298\u001b[0m im2\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m-> 3299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im1\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: images do not match"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "\n",
    "    # Print the attributes of the base clip\n",
    "    print(\"Base Clip Attributes:\", dir(base_clip))\n",
    "\n",
    "    # Set the duration of the base clip to the number of steps\n",
    "    base_duration = (num_steps / fps)*.05\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    # Print the updated duration of the base clip\n",
    "    print(\"Base Clip Duration (Updated):\", base_clip.duration)\n",
    "\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1 / num_steps\n",
    "    #step_size = .25 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(1,num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        print(i)\n",
    "        if i ==0:\n",
    "            size = (1, 1)\n",
    "        else:\n",
    "            Size = (int(width * (1.0 + i * step_size))/num_steps, int(height * (1.0 + i * step_size))/num_steps)\n",
    "            print(Size)\n",
    "        size = (i*10),(i*10)\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path =  \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, output_directory, num_steps):\n",
    "    base_image = Image.open(base_image_path).convert(\"RGBA\")\n",
    "    overlay_image = Image.open(overlay_image_path).convert(\"RGBA\")\n",
    "\n",
    "    width, height = base_image.size\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = int(i * (255 * step_size))\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay = overlay_image.resize(size, Image.BICUBIC)\n",
    "\n",
    "        # Create a new image with the same size as the base image\n",
    "        new_image = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n",
    "\n",
    "        # Overlay the resized overlay image on the new image with the calculated opacity\n",
    "        new_image = Image.alpha_composite(new_image, resized_overlay)\n",
    "\n",
    "        # Overlay the new image on the base image with the calculated opacity\n",
    "        final_image = Image.alpha_composite(base_image, new_image)\n",
    "\n",
    "        # Save the image with the current step number as the filename\n",
    "        output_path = os.path.join(output_directory, f\"{i:03d}.png\")\n",
    "        final_image.save(output_path)\n",
    "\n",
    "    return output_directory\n",
    "\n",
    "def create_overlay_video(image_directory, output_video_path, fps):\n",
    "    input_stream = ffmpeg.input(os.path.join(image_directory, \"%03d.png\"), framerate=fps)\n",
    "    ffmpeg.output(input_stream, output_video_path).run()\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n",
    "\n",
    "output_directory = \"output_images\"\n",
    "output_video_path = \"output_video.mp4\"\n",
    "num_steps = 200\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay images\n",
    "overlay_images(base_image_path, overlay_image_path, output_directory, num_steps)\n",
    "\n",
    "# Create the video from the overlay images\n",
    "create_overlay_video(output_directory, output_video_path, fps)\n",
    "overlay_image_path = \"/home/jack/Desktop/learn_flask/static/screaming/00069.jpg\"\n",
    "output_video_path = \"output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af1e768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLC media player 3.0.11.1 Vetinari (revision 3.0.11.1-0-g52483f3ca2)\n",
      "[\u001b[32;1m0000000000aad1a0\u001b[0m] main libvlc: \u001b[0;1mRunning vlc with the default interface. Use 'cvlc' to use vlc without interface.\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f50ac001840\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f50ac001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f50ac001840\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "[\u001b[32;1m00007f50c0c12e60\u001b[0m] avcodec decoder: \u001b[0;1mUsing G3DVL VDPAU Driver Shared Library version 1.0 for hardware decoding\u001b[0m\n",
      "\u001b[0;36m[h264 @ 0x7f50c0c1bdc0] \u001b[0m\u001b[1;31mFailed setup for format vdpau: hwaccel initialisation returned error.\n",
      "\u001b[0m[\u001b[32;1m00007f50c0c12e60\u001b[0m] avcodec decoder error: \u001b[31;1mexisting hardware acceleration cannot be reused\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so\n",
      "libva error: /usr/lib/x86_64-linux-gnu/dri/nouveau_drv_video.so has no function __vaDriverInit_0_32\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f50ac766b40\u001b[0m] glconv_vaapi_x11 gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f50ac766b40\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "libva info: VA-API version 0.39.0\n",
      "libva info: va_getDriverName() returns 0\n",
      "libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/gallium_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[\u001b[32;1m00007f50ac766b40\u001b[0m] glconv_vaapi_drm gl error: \u001b[31;1mvaInitialize: unknown libva error\u001b[0m\n",
      "QObject::~QObject: Timers cannot be stopped from another thread\n"
     ]
    }
   ],
   "source": [
    "!vlc output_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa02db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0899cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Clip Attributes: ['_TEMP_FILES_PREFIX', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'add_mask', 'afx', 'aspect_ratio', 'audio', 'audio_fadein', 'audio_fadeout', 'audio_normalize', 'blit_on', 'close', 'copy', 'crop', 'crossfadein', 'crossfadeout', 'cutout', 'duration', 'end', 'fadein', 'fadeout', 'fill_array', 'fl', 'fl_image', 'fl_time', 'fx', 'get_frame', 'h', 'has_constant_size', 'img', 'invert_colors', 'ipython_display', 'is_playing', 'ismask', 'iter_frames', 'loop', 'make_frame', 'margin', 'mask', 'mask_and', 'mask_or', 'memoize', 'memoize_frame', 'memoized_t', 'on_color', 'pos', 'preview', 'relative_pos', 'resize', 'rotate', 'save_frame', 'set_audio', 'set_duration', 'set_end', 'set_fps', 'set_ismask', 'set_make_frame', 'set_mask', 'set_memoize', 'set_opacity', 'set_pos', 'set_position', 'set_start', 'show', 'size', 'speedx', 'start', 'subclip', 'subfx', 'to_ImageClip', 'to_RGB', 'to_gif', 'to_images_sequence', 'to_mask', 'to_videofile', 'volumex', 'w', 'without_audio', 'write_gif', 'write_images_sequence', 'write_videofile']\n",
      "Base Clip Duration (Updated): 0.16666666666666669\n",
      "Concatenation successful!\n",
      "Moviepy - Building video output_video.mp4.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n",
      "Video writing successful!\n",
      "Overlay video created successfully!\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageClip, CompositeVideoClip, concatenate_videoclips\n",
    "\n",
    "def overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps):\n",
    "    base_clip = ImageClip(base_image_path)\n",
    "\n",
    "    # Print the attributes of the base clip\n",
    "    print(\"Base Clip Attributes:\", dir(base_clip))\n",
    "\n",
    "    # Set the duration of the base clip to the number of steps\n",
    "    base_duration = (num_steps / fps)*.05\n",
    "    base_clip = base_clip.set_duration(base_duration)\n",
    "\n",
    "    # Print the updated duration of the base clip\n",
    "    print(\"Base Clip Duration (Updated):\", base_clip.duration)\n",
    "\n",
    "    overlay_clip = ImageClip(overlay_image_path, transparent=True)\n",
    "\n",
    "    width, height = base_clip.w, base_clip.h\n",
    "    step_size = 1.0 / num_steps\n",
    "\n",
    "    clips = []\n",
    "    for i in range(num_steps + 1):\n",
    "        # Calculate current opacity and size\n",
    "        opacity = i * step_size\n",
    "        size = (int(width * (1.0 + i * step_size)), int(height * (1.0 + i * step_size)))\n",
    "\n",
    "        # Resize the overlay image\n",
    "        resized_overlay_clip = overlay_clip.resize(size)\n",
    "\n",
    "        # Set the opacity of the overlay clip\n",
    "        resized_overlay_clip = resized_overlay_clip.set_opacity(opacity)\n",
    "\n",
    "        # Composite the overlay clip on the base clip\n",
    "        composite_clip = CompositeVideoClip([base_clip.copy(), resized_overlay_clip], use_bgclip=True)\n",
    "\n",
    "        # Set the duration of the composite clip to match the base clip\n",
    "        composite_clip = composite_clip.set_duration(base_duration)\n",
    "\n",
    "        clips.append(composite_clip)\n",
    "\n",
    "    try:\n",
    "        # Concatenate all clips to create the final video\n",
    "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while concatenating clips:\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Write the video to a file in MP4 format\n",
    "        final_clip.write_videofile(output_video_path, fps=fps, codec='libx264', audio=False)\n",
    "        print(\"Video writing successful!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing the output video:\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Overlay video created successfully!\")\n",
    "\n",
    "# Rest of the script remains the same\n",
    "\n",
    "# Paths and parameters\n",
    "base_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "overlay_image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "output_video_path = \"zooms/output_video.mp4\"  # Change the extension to \".mp4\"\n",
    "num_steps = 100\n",
    "fps = 30\n",
    "\n",
    "# Create the overlay video\n",
    "overlay_images(base_image_path, overlay_image_path, num_steps, output_video_path, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6de680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images_with_opacity_and_zoom(image_path, num_images):\n",
    "    original_image = Image.open(image_path).convert(\"RGBA\")\n",
    "    w, h = original_image.size\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inc = (i + 1) / num_images\n",
    "        opacity = int(255 * inc)\n",
    "\n",
    "        # Create a new transparent image with increased size for each iteration\n",
    "        new_size = (int(w + w * inc), int(h + h * inc))\n",
    "        final_image = Image.new(\"RGBA\", new_size, (0, 0, 0, 0))\n",
    "\n",
    "        # Calculate the top-left coordinates to center the original image on the final image\n",
    "        x_offset = (new_size[0] - w) // 2\n",
    "        y_offset = (new_size[1] - h) // 2\n",
    "\n",
    "        # Paste the original image onto the final image at the calculated coordinates\n",
    "        final_image.paste(original_image, (x_offset, y_offset))\n",
    "\n",
    "        # Resize the original image to the desired size\n",
    "        resized_original = original_image.resize((int(w * inc), int(h * inc)), Image.BICUBIC)\n",
    "\n",
    "        # Calculate the top-left coordinates to center the overlay image on the final image\n",
    "        x_overlay_offset = (new_size[0] - resized_original.width) // 2\n",
    "        y_overlay_offset = (new_size[1] - resized_original.height) // 2\n",
    "\n",
    "        # Create a new transparent image to hold the overlay\n",
    "        overlay_image = Image.new(\"RGBA\", new_size, (0, 0, 0, 0))\n",
    "\n",
    "        # Paste the resized overlay image onto the transparent image at the calculated coordinates\n",
    "        overlay_image.paste(resized_original, (x_overlay_offset, y_overlay_offset))\n",
    "\n",
    "        # Set the opacity for the overlay image\n",
    "        overlay_image.putalpha(opacity)\n",
    "\n",
    "        # Composite the overlay image with the final image\n",
    "        final_image = Image.alpha_composite(final_image, overlay_image)\n",
    "        DIR = \"zooms/\"\n",
    "        file_number = str(i + 1).zfill(5)\n",
    "        output_path = f\"{DIR}{file_number}.png\"\n",
    "        final_image.save(output_path)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/home/jack/Desktop/StoryMaker/static/images/Elektra-Weapons/00059.jpg\"\n",
    "num_images = 4  # Change this to the desired number of images in the sequence\n",
    "\n",
    "overlay_images_with_opacity_and_zoom(image_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/jack/hidden/MUSIC.py\n",
    "import glob\n",
    "import random\n",
    "def music():\n",
    "    MUSIC = random.choice(glob.glob(\"/home/jack/Desktop/HDD500/collections/Music/*.mp3\"))\n",
    "    return MUSIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc2d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloned-base",
   "language": "python",
   "name": "cloned-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
